\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}


\usepackage{graphicx}
\usepackage{theorem}        %%Lo agregue yo <========================================
\usepackage{algorithm}      %%Lo agregue yo <========================================
\usepackage{algorithmic}        %%Lo agregue yo <========================================
\usepackage{amssymb, amsmath}



\newtheorem{mytheorem}{Theorem}
\newtheorem{example}{Example}[section]  %\newtheorem{ambiente}{título}[numeração] 
\newtheorem{definition}[mytheorem]{Definition}
\newtheorem{proposition}[mytheorem]{Proposition}
\newtheorem{corollary}[mytheorem]{Corollary}
\newtheorem{mylemma}[mytheorem]{Lemma}
\newtheorem{conjecture}[mytheorem]{Conjecture}
\newenvironment{myproof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{color}                          % colors
\usepackage{framed}                         % frames
\usepackage{mdframed}                       % better frames
\usepackage{fancyhdr}                       % Fancy headings

\definecolor{thmBgColor}{RGB}{250,250,250}
\definecolor{thmLnColor}{RGB}{200,200,200}

\mdfdefinestyle{MDFStyGrayScreen}{%
    linecolor=thmLnColor,
        backgroundcolor=thmBgColor,
        linewidth=1pt,
        topline=true,
    bottomline=true,
    rightline=false,
        leftline=false,
    outerlinewidth=2pt,
    roundcorner=0pt,
    innertopmargin=4pt, %\baselineskip
    innerbottommargin=4pt, %\baselineskip,
    innerrightmargin=3pt,
    innerleftmargin=3pt,
        skipabove=\topskip,
        skipbelow=\topskip,
        nobreak=true
        }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%opening
\title{Demonstrations Database}
\author{Fernando Pujaico Rivera}

\begin{document}

\maketitle

\begin{abstract}
This article have a set of demonstrations necessary for other articles
\end{abstract}

\section{System Model}
\label{Sec:system}

System model of system studied in this article in Fig. \ref{fig:Model}, where
$Pr(U_0=1)=0.5$ then consequently $Pr(U_m=1)=0.5$ $\forall m \in \{1, ..., M\}$.
\begin{figure}[h!bt]
\centering \includegraphics[width=12cm]{{fig1.eps}}
\caption{System model.}
\label{fig:Model}
\end{figure}

\section{Demonstrations}
\label{Sec:Demons}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{definition}
 \label{def:omega}
Let $\Omega_m$, $\forall m \in \{1,$ $2,$ $...,$ $M\}$, be a set of correlated 
sources as
\begin{equation}
\label{eq:omega}
 \Omega_m \equiv U_1 U_2 ... U_m,
\end{equation}
with the especial case with $\Omega_0$ equal to null,
where each source $U_i$, $\forall$ $i \in$ $\{1,$ $2,$ $...,$ $m\}$, is created 
passing the source $U_0$, $Pr(U_0=1)=0.5$, across a BSC channel  with error 
probability $Pr(U_i \ne U_0 | U_0)=p_i$.

In this line, also is defined a set of correlated sources $\Omega^{M}_m$, 
$\forall m \in \{1,$ $2,$ $...,$ $M\}$, as anything set of $m$  sources in $\Omega_M$, 
with the especial case with $\Omega^M_0$ equal to null.
\end{definition}
\end{mdframed}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{definition}
 \label{def:hb}
The binary entropy is defined as $h_b(\rho)$, such that
\begin{equation}
\label{eq:hb1}
h_b(\rho)=- \rho ~ log_2(\rho) - (1-\rho) ~ log_2(1-\rho).
\end{equation}
If the probability $p_m$ is used, then is defined
\begin{equation}
\label{eq:hi}
h_m \equiv h_b(p_m)
\end{equation}
\end{definition}
\end{mdframed}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
\label{lemma:def} 
If we defined 
\begin{equation} \label{eq:ab2}
 p_a || p_b \equiv p_a + p_b -2 p_a p_b, 
\end{equation} 
then the operator $||$ is an associative operator such that
\begin{equation} \label{eq:def1}
 (p_a || p_b)||p_c = p_a || (p_b||p_c)
\end{equation} 
\end{mylemma}
\end{mdframed}
\begin{myproof}
\label{proof:def}
\begin{equation} \label{eq:def2}
\begin{matrix}
(p_a || p_b)||p_c & = & p_a + p_b + p_c -2 p_a p_b -2 p_b p_c  \\
~                 & ~ & -2 p_a p_c + 4 p_a p_b p_c.
\end{matrix}
\end{equation} 
If we developing similarly $p_a || (p_b||p_c)$ we reached the same result, and 
the Lemma \ref{lemma:def} is proved.
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
\label{lemma:psimple} 
Known 2 probabilities $p_1$, and $p2$
them is true that
\begin{equation} \label{eq:psimple1}
h_b(p_1) \leq h_b(p_1||p_2) 
\end{equation}
\end{mylemma}
\end{mdframed}
\begin{myproof}
\label{proof:psimple} 
We know  by Jensen's inequality \cite{cover} that for a concave function $f(.)$ 
is true that
\begin{equation} \label{eq:psimple2}
(1-\lambda) f(p_1) +\lambda f(1-p_1)  \leq f((1-\lambda) p_1 +\lambda (1-p_1))
\end{equation}
replacing the function $f(.)$ by the concave function $h_b(.)$ and $\lambda$ 
by $p_2$ we obtain
\begin{equation} \label{eq:psimple3}
h_b(p_1)  \leq h_b(p_2 + p_1 - 2 p_1 p_2)
\end{equation}
and the lemma is proved.
%and finally
%\begin{equation} \label{eq:psimple4}
%h_b(p_1)  \leq h_b(p_1|| p_2).
%\end{equation}
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
\label{lemma:ppapb} 
Known 3 probabilities $p_a$, $p_b$ and $p$, where
\begin{equation} \label{eq:ppapb0}
h_b(p_a) \leq h_b(p_b) 
\end{equation}
them is true that
\begin{equation} \label{eq:ppapb1}
h_b(p||p_a) \leq h_b(p||p_b) 
\end{equation}
\end{mylemma}
\end{mdframed}

\begin{myproof}
\label{proof:ppapb} 
Using the Lemma \ref{lemma:def} and \ref{lemma:psimple}, and replacing 
$p_1$ by $p || p_a$, the equation (\ref{eq:psimple1}) can be rewrite as 
\begin{equation} \label{eq:ps1}
h_b(p || p_a) \leq h_b(p|| (p_a||p_2)).
\end{equation}
If we call to $p_a||p_2$ as $p_b$, and it is replace in (\ref{eq:ps1}) we obtain
the same equation that in (\ref{eq:ppapb1}) and the lemma is proved.
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
\label{lemma:twoparbsc}
Known two correlated binary sources $U_a$ and $U_b$ that are created passing 
the binary source $U_0$, $Pr(U_0=1)=0.5$, through of two BSC channels with  
error probabilities $p_a$ and $p_b$ respectively. These can be modeled as a 
source $U_b$ that is created passing the source $U_a$ through of one BSC 
channel with  error probability 
\begin{equation} \label{eq:tpb0}
Pr(U_b \neq U_a|U_a)=P_a || P_b.
\end{equation}
\end{mylemma}
\end{mdframed}

\begin{myproof}
\label{proof:twoparbsc}
The equation (\ref{eq:tpb0}) imply to prove that 
\begin{equation} \label{eq:tpb1}
Pr(U_b=1|U_a=0)=Pr(U_b=0|U_a=1).
\end{equation}
Development both parts we obtain
\small
\begin{equation} \label{eq:tpb2}
\begin{matrix}
Pr(U_b=1|U_a=0) & = & \frac{Pr(U_b=1,U_a=0)}{Pr(U_a=0)}\\ 
 ~              & = & \frac{Pr((U_b=1,U_a=0)|U_0=0)Pr(U_0=0)}{Pr(U_a=0)}\\ 
 ~              & + & \frac{Pr((U_b=1,U_a=0)|U_0=1)Pr(U_0=1)}{Pr(U_a=0)}\\
 ~              & = & \frac{Pr(U_b=1|U_0=0)Pr(U_a=0|U_0=0)Pr(U_0=0)}{Pr(U_a=0)}\\ 
 ~              & + & \frac{Pr(U_b=1|U_0=1)Pr(U_a=0|U_0=1)Pr(U_0=1)}{Pr(U_a=0)}\\
 ~              & = & p_b(1-p_a)+(1-p_b)p_a\\ 
 ~              & = & p_a+p_b -2 p_a p_b,
\end{matrix}
\end{equation}
\normalsize
in the other hand similarly to (\ref{eq:tpb2}) we obtain that 
$Pr(U_b=1|U_a=1)=P_a || P_b$. Thus, the Lemma \ref{lemma:twoparbsc} is proved.
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
\label{lemma:minimo}
We consider that have $\hat{\Omega}_{m}$ as a set of sources that pertain 
$\Omega_M$, also $U_{a}$ and $U_b$, $\forall b \geq {a}$, are sources that 
pertain to $\Omega_M$ but not to $\hat{\Omega}_{m}$, such that $ h_b(p_a) \leq h_b(p_b)$
then
\begin{equation}\label{eq:proof1}
 H(\hat{\Omega}_{m} U_{a} ) \leq H(\hat{\Omega}_{m} U_b ),
\end{equation}
\end{mylemma}
\end{mdframed}

\begin{myproof}
\label{proof:minimo}
The equation (\ref{eq:proof1}) is equivalent to
\begin{equation}\label{eq:proof2}
 H( U_{a}| \hat{\Omega}_{m}) \leq H(U_b| \hat{\Omega}_{m} ).
\end{equation} 
$\hat{\Omega}_{m}$  only have a relation with $U_a$ and $U_b$ through of $U_0$. The
known of $\hat{\Omega}_{m}$ only give a distorted known of source $U_0$, this
distorted source is called here as $\tilde{U}_0$ and can be modeled as
 if the source $\tilde{U}_0$ was created passing the source $U_0$ through of
a BSC channel with error probability $p_{\hat{\Omega}_{m}}$, that only depend of 
$\hat{\Omega}_{m}$. Thus, the equation (\ref{eq:proof2}) can be rewrite as 
\begin{equation}\label{eq:proof3}
 H( U_{a}| \tilde{U}_0) \leq H(U_b| \tilde{U}_0 ).
\end{equation} 
Using the Lemma \ref{lemma:twoparbsc} the last equation can be rewrite as
\begin{equation}\label{eq:proof4}
h_b( p_{\hat{\Omega}_{m}}||p_{a} ) \leq h_b( p_{\hat{\Omega}_{m}}||p_{b} ).
\end{equation} 
For definition of problem we know that $h_b(p_a) \leq h_b(p_b)$. Using the 
Lemma \ref{lemma:ppapb}, we can demonstrate that (\ref{eq:proof4}) is true
and consequently (\ref{eq:proof1}) too. 
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
 \label{lemm:PrA}
Known a set of $m$ correlated  sources  $\Omega_m$. Then, is true that
\begin{equation}\label{eq:PA}
Pr(\Omega_m=\mathbf{a})=\frac{ \Psi(\mathbf{a}) + \Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
\begin{equation}\label{eq:PAequiv}
\Psi(\mathbf{a}) \equiv \prod \limits_{i=1}^{m}{Pr(U_i=a_i|U_0=0)}.
\end{equation}
being $\mathbf{a}=\{a_1, a_2, ..., a_m\}$ and $\mathbf{\bar{a}}$ two 
binary vectors, both with $m$ elements, where $\mathbf{\bar{a}}\oplus \mathbf{a}=\mathbf{0}$. 
\end{mylemma}
\end{mdframed}

\begin{myproof}
 \label{proof:PrA} 
\begin{equation}\label{eq:PA1}
\begin{matrix}
Pr(\Omega_m=\mathbf{a})&=&Pr(\Omega_m=\mathbf{a}|U_0=0)Pr(U_0=0)\\
~                 &+&Pr(\Omega_m=\mathbf{a}|U_0=1)Pr(U_0=1), 
\end{matrix}
\end{equation}
\begin{equation}\label{eq:PA2}
Pr(\Omega_m=\mathbf{a})=\frac{Pr(\Omega_m=\mathbf{a}|U_0=0)+Pr(\Omega_m=\mathbf{a}|U_0=1)}{2},
\end{equation}
when $U_0$ is known the probabilities of sources in $\Omega_m$ are independents,
\begin{equation}\label{eq:PA3}
Pr(\Omega_m=\mathbf{a})=\frac{\prod \limits_{U_i\in \Omega_m}{Pr(U_i=a_i|U_0=0)}+\prod \limits_{U_i\in \Omega_m}{Pr(U_i=a_i|U_0=1)}}{2},
\end{equation}
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
 \label{lemm:dhdrho}
Known the binary entropy $h(\rho)=-\rho log_2(\rho)-(1-\rho) log_2(1-\rho)$ then
\begin{equation}\label{eq:dhdrho1}
 \frac{\partial h(\rho)}{\partial \rho}= log_2 \left( \frac{1-\rho}{\rho} \right )
\end{equation}
\end{mylemma}
\end{mdframed}

\begin{myproof}
 \label{proof:dhdrho} 
\begin{equation}\label{eq:dhdrho2}
 \frac{\partial h(\rho)}{\partial \rho}= - log_2(\rho)+ log_2(1-\rho)
\end{equation}
\end{myproof}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
\label{lemm:hpi} 
The value of entropy function $H(\Omega_m)$ is the same for a set of sources
$U_i$ with $Pr(U_i\neq U_0|U_0)$ equal to $p_i$ or $1-p_i$
\end{mylemma}
\end{mdframed}
\begin{myproof}
 \label{proof:hpi} 
Without loss of generality, we assume that need demonstrate $H(U_i\Omega_{m})$
is the same for $Pr(U_i\neq U_0|U_0)$ equal to $p_i$ or $1-p_i$.
\begin{equation}\label{eq:hpi1}
\begin{matrix}
H(U_i\Omega_{m})\\
=\sum \limits_{U_i,\Omega_{m}} Pr(U_i\Omega_{m}) log_2(Pr(U_i\Omega_{m})) ~~~~~~~~~~~~~~~~~~~~\\
=\sum \limits_{\mathbf{a}} Pr(U_i=1,\Omega_{m}=\mathbf{a}) log_2(Pr(U_i=1,\Omega_{m}=\mathbf{a}))\\
+\sum \limits_{\mathbf{a}} Pr(U_i=0,\Omega_{m}=\mathbf{a}) log_2(Pr(U_i=0,\Omega_{m}=\mathbf{a}))
\end{matrix}
\end{equation}
Using the Lemma \ref{lemm:PrA} we know that for the case of $Pr(U_i\neq U_0|U_0)=p_i$ 
\begin{equation}\label{eq:hpi2}
Pr(U_i=1,\Omega_m=\mathbf{a})=\frac{ p_i\Psi(\mathbf{a}) + (1-p_i)\Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
\begin{equation}\label{eq:hpi3}
Pr(U_i=0,\Omega_m=\mathbf{a})=\frac{ (1-p_i)\Psi(\mathbf{a}) + p_i\Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
and for the case of $Pr(U_i\neq U_0|U_0)=1-p_i$
\begin{equation}\label{eq:hpi4}
Pr(U_i=1,\Omega_m=\mathbf{a})=\frac{ (1-p_i)\Psi(\mathbf{a}) + p_i\Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
\begin{equation}\label{eq:hpi5}
Pr(U_i=0,\Omega_m=\mathbf{a})=\frac{ p_i\Psi(\mathbf{a}) + (1-p_i)\Psi(\mathbf{\bar{a}}) }{2}.
\end{equation}
Using this results is easy see that for both case  we obtain the same value of 
$H(U_i\Omega_{m})$.
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{corollary}
 \label{coro:hpi} 
Follow the Lemma \ref{lemm:hpi}, for calculate the joint entropy $H(\Omega_m)$ 
we can assume that all probabilities $p_i \leq 1/2$. Thus, exist a bijective 
function that link the probability $p_i$ an the binary entropy $h_i$. Therefore
the joint entropy $H(\Omega_m)$ is a function that depend of $\mathbf{h}=\{h_1, h_2, ..., h_m\}$.
\end{corollary}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
 \label{lemm:dH}
Known a set of $m$ correlated  sources  $\Omega_m$. Then, is true that
the value of entropy $H(\Omega_m)$ grow in relation growing of $h_b(p_i)$, 
$\forall i$ $\in \{1,$ $2,$ $...,$ $m\}$,
\begin{equation}\label{eq:dH1}
 \frac{\partial H(\Omega_m)}{\partial h_i} \geq 0
\end{equation}
\end{mylemma}
\end{mdframed}

\begin{myproof}
 \label{proof:dH} 
For the Corollary \ref{coro:hpi} we know that $H(\Omega_m)$ depend of $h_i$
and this depend of $p_i$. Without loss of generality, 
we assume that need demonstrate
$({\partial H(U_j\Omega_{m})}/{\partial p_j}) ({\partial p_j}/{\partial h_j}) \geq 0$,
being that $U_j \notin \Omega_{m}$. Thus,
\small
\begin{equation}\label{eq:dH2}
 \frac{\partial H(U_j\Omega_{m})}{\partial h_j} =\frac{-\partial \sum \limits_{U_j,\Omega_{m}} Pr(U_j\Omega_{m}) log_2(Pr(U_j\Omega_{m}))}{\partial p_j}\frac{\partial p_j}{\partial h_j} 
\end{equation}
\normalsize
%\small
\begin{equation}\label{eq:dH21}
\begin{matrix}
\frac{\partial H(U_j\Omega_{m})}{\partial h_j} =\\
-\frac{\partial \sum \limits_{\mathbf{a}} Pr(U_j=1,\Omega_{m}=\mathbf{a}) log_2(Pr(U_j=1,\Omega_{m}=\mathbf{a}))}{\partial p_j}\frac{\partial p_j}{\partial h_j}  \\
-\frac{\partial \sum \limits_{\mathbf{a}} Pr(U_j=0,\Omega_{m}=\mathbf{a}) log_2(Pr(U_j=0,\Omega_{m}=\mathbf{a}))}{\partial p_j}\frac{\partial p_j}{\partial h_j}
\end{matrix}
\end{equation}
%\normalsize
and using the Lemma \ref{lemm:PrA} we obtain
\begin{equation}\label{eq:dH3}
 Pr(U_j=1,\Omega_{m}=\mathbf{a})=\frac{ p_j\Psi(\mathbf{a}) + (1-p_j)\Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
\begin{equation}\label{eq:dH4}
 Pr(U_j=0,\Omega_{m}=\mathbf{a})=\frac{ (1-p_j)\Psi(\mathbf{a}) + p_j\Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
\begin{equation}\label{eq:dH6}
 \frac{\partial Pr(U_j=1,\Omega_{m}=\mathbf{a})}{\partial p_j}=\frac{ \Psi(\mathbf{a}) -\Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
\begin{equation}\label{eq:dH7}
 \frac{\partial Pr(U_j=0,\Omega_{m}=\mathbf{a})}{\partial p_j}=-\frac{ \Psi(\mathbf{a}) -\Psi(\mathbf{\bar{a}}) }{2},
\end{equation}
\begin{equation}\label{eq:dH5}
 \frac{\partial h_j}{\partial p_j}=log_2 \left( \frac{1-p_j}{p_j}\right),
\end{equation}
using (\ref{eq:dH3}), (\ref{eq:dH4}), (\ref{eq:dH6}), (\ref{eq:dH7}) and (\ref{eq:dH5}) in (\ref{eq:dH21})
\begin{equation}\label{eq:dH22}
\frac{\partial H(U_j\Omega_{m})}{\partial h_j} = \sum \limits_{\mathbf{a}} f(p_j,\mathbf{a})
\end{equation}
\begin{equation}\label{eq:dH23}
f(p_j,\mathbf{a}) = \frac{ \Psi(\mathbf{a}) -\Psi(\mathbf{\bar{a}}) }{2~log_2 \left( \frac{1-p_j}{p_j}\right)} log_2\left( \frac{ (1-p_j)\Psi(\mathbf{a}) + p_j\Psi(\mathbf{\bar{a}}) }{ p_j\Psi(\mathbf{a}) + (1-p_j)\Psi(\mathbf{\bar{a}}) }\right)
\end{equation}
if $p_j=1/2$, then
\begin{equation}\label{eq:dH24}
f(1/2,\mathbf{a}) = \frac{1}{2}\frac{ (\Psi(\mathbf{a}) -\Psi(\mathbf{\bar{a}}))^2 }{\Psi(\mathbf{a}) + \Psi(\mathbf{\bar{a}})} \geq 0.
\end{equation}
Analyzing the equation (\ref{eq:dH23}) for $p_j<1/2$, $p_j>1/2$, 
$\Psi(\mathbf{a}) \leq \Psi(\mathbf{\bar{a}})$ and $\Psi(\mathbf{a}) > \Psi(\mathbf{\bar{a}})$,
can be seen that $f(p_j,\mathbf{a})$ is ever positive, thus the Lemma \ref{lemm:dH} 
is proved.
\end{myproof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{corollary}
 \label{corol:dH}  We know that  $H(\Omega_m)$
is in function of $\mathbf{h}=\{h_1, h_2, ..., h_m\}$, thus 
$H(\Omega_m) = \phi(\mathbf{h})$, where $\phi(.)$ is a $m$-dimensional function.
Follow the Lemma \ref{lemm:dH} we know that
\begin{equation}\label{eq:coro1}
\phi(\mathbf{h}) \leq \phi(\mathbf{h} +  \mathbf{\triangle h}) 
\end{equation}
when the elements of $\mathbf{\triangle h}$ are higher or equal to zero.
\end{corollary}
\end{mdframed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
 \label{lemm:H}
 Known a system model as Fig. \ref{fig:Model}, then
  \begin{equation}\label{eq:H}
H(\Omega_m) = \sum_{i=1}^{m}{h_b(p_i)}+1-H(U_0|\Omega_m).
\end{equation}
\end{mylemma}
\end{mdframed}

\begin{myproof}
 \label{proof:H}
 Knowing that
 \begin{equation}\label{eq:H1}
H(A B)=H(A|B)+H(B)=H(B|A)+H(A),
\end{equation}
then
 \begin{equation}\label{eq:H2}
H(\Omega_m|U_0)+H(U_0)=H(U_0|\Omega_m)+H(\Omega_m)
\end{equation}
 \begin{equation}\label{eq:H3}
H(\Omega_m) = H(\Omega_m|U_0)+H(U_0)-H(U_0|\Omega_m)
\end{equation}
 \begin{equation}\label{eq:H4}
H(\Omega_m) = \sum_{i=1}^{m}{H(U_i|U_0)}+1-H(U_0|\Omega_m)
\end{equation}
\end{myproof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
 \label{lemm:Hin}
 Known a system model as Fig. \ref{fig:Model} with $Pr(U_0=1)=0.5$. Then is true that
  \begin{equation}\label{eq:Hin}
\sum_{i=1}^{M}{h_b(p_i)}+1-h_b(p_a) \leq H(\Omega_m) \leq \sum_{i=1}^{M}{h_b(p_i)}+1.
\end{equation}
\end{mylemma}
\end{mdframed}


\begin{myproof}
 \label{proof:Hin}
 Knowing 
\begin{equation}\label{eq:Hin1}
\begin{matrix}
 H_{min} & \leq & H(U_0|\Omega_m) & \leq & H_{max}       & ~    & ~\\
 0       & \leq & ~               & \leq & H(U_0|U_aU_b) & \leq &H(U_0|U_a)
\end{matrix}
\end{equation}
$\forall a,b \in \{1, ..., M\}$, and the Lemma \ref{lemm:H} them is true that
\begin{equation}\label{eq:Hin2}
 \sum_{i=1}^{M}{h_b(p_i)}+1 -H_{max} \leq H(\Omega_m) \leq \sum_{i=1}^{M}{h_b(p_i)}+1
\end{equation}

 Knowing (\ref{eq:H1}) have,  
 \begin{equation}\label{eq:Hin4}
\begin{matrix}
 H(U_0|U_a)&=&H(U_a|U_0)\\
       ~  &=&h_b(p_a)
\end{matrix}
\end{equation}
and 
\begin{equation}\label{eq:Hin5}
\begin{matrix}
H(U_0|U_aU_b) & = & H(U_a|U_0) + H(U_b|U_0) + H(U_0)- H(U_aU_b)  \\
 ~            & = & h_b(p_a) + h_b(p_b) - h_b(p_a||p_b)
 \end{matrix}.
\end{equation}
The minimum value for $H_{max}=h_b(p_a) + h_b(p_b) - h_b(p_a||p_b)$ being 
$\{p_a,p_b\}$ the smallest probabilities of all $p_i, \forall i \in \{1, ..., M\}$ 
\end{myproof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
 \label{lemm:h0OmegaM_1}
 Known a system model as Fig. \ref{fig:Model} and an additional binary source $U_j$, so that $P(U_j\neq U_0|U_0)=\rho_j$, then
\begin{equation}\label{eq:h0OmegaM_1_a}
H(U_0|\Omega_M U_j) = h(\rho_j),
\end{equation}
\begin{equation}\label{eq:h0OmegaM_1_a2}
H(\Omega_M U_j) = M+1,
\end{equation}
when $\rho_m=0.5, \forall~1 \leq m\leq M$.
\end{mylemma}
\end{mdframed}

\begin{myproof}
 \label{proof:h0OmegaM_1}
 Knowing the Lemma \ref{lemm:H} we have that:
\begin{equation}\label{eq:h0OmegaM_1_b}
H(U_0|\Omega_M U_j) +H( \Omega_M U_j)=1 + h(\rho_j)+ \sum \limits_m h(\rho_m),
\end{equation}
and given that $\rho_m=0.5$, then
\begin{equation}\label{eq:h0OmegaM_1_b2}
H(U_0|\Omega_M U_j) +H( \Omega_M U_j)=1 + M + h(\rho_j).
\end{equation}
By other side, we know that $H( \Omega_M U_j)=H( \Omega_M|U_j)+H(U_j)$,
and given that $H(U_j)=1$ and $H( \Omega_M|U_j)=H( \Omega_M)=M$;
then $H( \Omega_M U_j)=M+1$.

Finally we can say that,
\begin{equation}\label{eq:h0OmegaM_1_c}
H(U_0|\Omega_M U_j) = h(\rho_j).
\end{equation}
\end{myproof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mylemma}
 \label{lemm:h0OmegaM_1a}
 Known a system model as Fig. \ref{fig:Model} and defined $h(\rho) \equiv H(U_0|U_m)=H(U_m|U_0)$ and 
 $h_{C}(\rho,M)\equiv H(U_0|\Omega_M)$ when $\rho_m=\rho$, then
  \begin{equation}\label{eq:h0OmegaM_1a_1}
h(\rho) \geq h_{C}(\rho,M) > h_{C}(\rho,M+1)
\end{equation}
\end{mylemma}
\end{mdframed}

\begin{myproof}\label{proof:h0OmegaM_1a}
From the data processing inequality \cite{dpi}, we know
 \begin{equation}
  H(A|B) >  H(A|BC)
 \end{equation}
 the same way we can say that
 \begin{equation}
  H(U_0|\Omega_M) >  H(U_0|\Omega_M U_{M+1})
 \end{equation}
 where the source $U_{M+1}$ is a new binary source, so that $P(U_j\neq U_0|U_0)=\rho$.
 Consequently It is fulfill that,
 \begin{equation}\label{eq:h0OmegaM_1a_2}
h_{C}(\rho,M) > h_{C}(\rho,M+1).
\end{equation}
Finally $h_{C}(\rho,1)=H(U_0|U_1)=h(\rho)$; thus, the Eq. (\ref{eq:h0OmegaM_1a_1}), It is fulfill.
\end{myproof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Propositions}
\label{sec:Propositions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mytheorem}
 \label{prop:OmegaM}
 Known a system model as Fig. \ref{fig:Model} and defined $h_{J}(\rho,M)\equiv H(\Omega_M)$ 
 when $\rho_m=\rho$, then
 by the work in \cite[p.~37]{shomega}, we now that,
\begin{equation}\label{eq:OmegaMP1}
 h_{J} = -\sum_{k=0}^M \binom{M}{k}f(k)log_2( f(k) )
\end{equation}
\begin{equation}\label{eq:OmegaMP2}
f(k)=\frac{ \rho^k (1-\rho)^{M-k} + \rho^{M-k} (1-\rho)^k }{2}
\end{equation}
\end{mytheorem}
\end{mdframed}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mytheorem}
 \label{prop:h0OmegaM}
 Known a system model as Fig. \ref{fig:Model} and defined $h_{C}(\rho,M)\equiv H(U_0|\Omega_M)$ 
 when $\rho_m=\rho$, then
 by the work in \cite[p.~37]{shu0omega}, we now that,
\begin{equation}\label{eq:h0OmegaMP}
h_{C}(\rho,M)  = \sum_{k=0}^M \binom{M}{k} \rho^k (1-\rho)^{M-k} log_2\left ( 1 + \left\{\frac{\rho}{(1-\rho)}\right\}^{M-2k} \right )    
\end{equation}
\end{mytheorem}
\end{mdframed}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mytheorem}[De Moivre-Laplace theorem]
 \label{teo:MoivreLaplace}
As $M$ grows large, for $k$ in the neighborhood of $M\rho$ we can approximate
\begin{equation}\label{eq:MoivreLaplace}
 {M \choose k} \rho^{k}(1-\rho)^{M-k}\simeq \frac{1}{\sqrt{2\pi M\rho (1-\rho)}} e^{-\frac{(k-M\rho)^{2}}{2M\rho (1-\rho)}}, \qquad   1>\rho>0 
\end{equation}
\end{mytheorem}
\end{mdframed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{corollary}
 \label{coro:h0OmegaM}
 Known a system model as Fig. \ref{fig:Model} and defined $h_{C}(\rho,M)\equiv H(U_0|\Omega_M)$ 
 when $\rho_m=\rho$, we use the Theorem \ref{prop:h0OmegaM} and the De Moivre–Laplace theorem
 by the work in \cite[p.~37]{shu0omega}, we now that,
\begin{equation}\label{eq:h0OmegaMC}
h_{C}(\rho,M)  = \sum_{k=0}^M \frac{e^{-\frac{(k-M\rho)^2}{2M\rho(1-\rho)}}}{\sqrt{2\pi M \rho (1-\rho)}}  log_2\left ( 1 + \left\{\frac{\rho}{(1-\rho)}\right\}^{M-2k} \right )    
\end{equation}
\end{corollary}
\end{mdframed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{mytheorem}[Fano's inequality]
 \label{teo:FanoInequality}
Let the random variables $X$, and $ H(X)=\sum_{x}^{|{\mathcal {X}}|} P(x)log(P(x))$,
\begin{equation}\label{eq:FanoInequality1}
 H(X)\leq \log(|{\mathcal {X}}|), 
\end{equation}
where $|\mathcal {X}|$ denotes the size of the alphabet ${\mathcal {X}}$ of $X$.


 
Let the random variables $X$ and $Y$ represent input and output messages with a 
joint probability $P(x,y)$. 
Let e represent an occurrence of error; i.e.,  $X \neq {\tilde {X}}$, 
with $\tilde {X}=f(Y)$ being an approximate version of $X$. Fano's inequality is
\begin{equation}\label{eq:FanoInequality2}
 H(X|Y)\leq h(P_e)+P_e\log(|{\mathcal {X}}|-1), 
\end{equation}
where $P_e=P(X \neq {\tilde {X}})$.
\end{mytheorem}
\end{mdframed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Working}
\label{sec:working}


\subsection{Experimentalmente corroborado $H(U_0|\Omega_M)$ (conjetura de la potencia $h_b$)}
\label{subsec:h0OmegaM_2}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{conjecture}
 \label{lemm:h0OmegaM_2}
 Known a system model as Fig. \ref{fig:Model} and $h_{C}(\rho,m)\equiv H(U_0|\Omega_m)$ when $\rho_i=\rho$, then
\begin{equation}\label{eq:Hconjecture1}
h_{C}(\rho,m)  \stackrel{m \rightarrow \infty }{=} h(\rho)^{f(\rho)~m+g(\rho)}
\end{equation}
\end{conjecture}
\end{mdframed}

\subsection{Hypothesis sin testar $H(U_0|\Omega_M)$}
\label{subsec:h0OmegaM}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mylemma}
 \label{lemm:1}
  Known a system model as Fig. \ref{fig:Model} with $Pr(U_0=1)=0.5$. Then is known 
experimentally that
\begin{equation}
 \begin{matrix}
 H(U_0|\Omega_M)= & (-1)^{1+1} & \sum \limits_{a_1}         h_b(p_{a_1}) \\
 ~                & (-1)^{2+1} & \sum \limits_{a_1 a_2}     h_b(p_{a_1}||p_{a_2}) \\ 
 ~                & (-1)^{3+1}  & \sum \limits_{a_1 a_2 a_3} h_b(p_{a_1}||p_{a_2}||p_{a_3}) \\ 
 ~                & ~ & \vdots \\
 ~                & (-1)^{M+1}  & \sum \limits_{a_1 ... a_M} h_b(p_{a_1}|| ... ||p_{a_M}) 
 \end{matrix}
\end{equation}

\end{mylemma}
\begin{myproof}
Them
\end{myproof}

\section{Hipotesis fracasadas $H(U_0|\Omega_M)$ }
\label{subsec:h0OmegaM_2}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{mdframed}[style=MDFStyGrayScreen]
\begin{conjecture}[Convergencia a $\rho$ con $h_c(\rho_1,\rho_2)$ iterativo]
 \label{lemm:h0OmegaM_hc2}
 Known a system model as Fig. \ref{fig:Model} and $h_{C}(\rho,M)\equiv H(U_0|\Omega_M)$ 
 when $\rho_m=\rho$, $\forall m \in $ $\{1,$ $2,$ $\dots,$ $M\}$.
 
 Then to each $i=\{1,$ $2,$ $3,$ $\dots,$ $M/2\}$
\begin{equation}\label{eq:HconjectureHc2_1}
H \leftarrow h_c(\rho_{i},\rho_{M-i+1})
\end{equation}
\begin{equation}\label{eq:HconjectureHc2_2}
H \rightarrow h_c(\rho,2)
\end{equation}
\begin{equation}\label{eq:HconjectureHc2_3}
\rho_{i} \leftarrow \rho ~~\wedge~~ \rho_{M-i+1} \leftarrow \rho .
\end{equation}

Later
\begin{equation}\label{eq:HconjectureHc2_3}
\rho_{:} \leftarrow order\_ascending(\rho_{:})
\end{equation}

and repeat until that $\rho_m$ be equals.
\end{conjecture}
\end{mdframed}




\begin{thebibliography}{99}
\bibitem{cover}
T. M. Cover, and J. Thomas, \textit{Elements of Information Theory}, Wiley-Interscience, 2006.

\bibitem{shu0omega}
Heshmati, Ashkan   (2007) Data compression and transmission in Wireless Sensor Networks.  
Masters thesis, Concordia University. URL http://spectrum.library.concordia.ca/975271/ 
  
\bibitem{shomega}
Ferrari, G.; Martalo, M.; Abrardo, A.; Raheli, R., "Orthogonal multiple 
access and information fusion: How many observations are needed?," 
Information Theory and Applications Workshop (ITA), 2012 , vol., no., 
pp.311,320, 5-10 Feb. 2012. doi: 10.1109/ITA.2012.6181783
  
\bibitem{dpi}
Normand J. Beaudry and Renato Renner. 2012. An intuitive proof of the data processing inequality. 
Quantum Info. Comput. 12, 5-6 (May 2012), 432-441. https://arxiv.org/abs/1107.0740

\end{thebibliography}

\end{document}
